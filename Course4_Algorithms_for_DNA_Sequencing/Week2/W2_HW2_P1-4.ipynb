{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive exact match\n",
    "\n",
    "def naive(p, t):\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1):  # loop over alignments\n",
    "        match = True\n",
    "        for j in range(len(p)):  # loop over characters\n",
    "            if t[i+j] != p[j]:  # compare characters\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)  # all chars matched; record\n",
    "    return occurrences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_with_counts(p, t):\n",
    "    occurrences = []\n",
    "    num_alignments = 0\n",
    "    num_character_comparisons = 0\n",
    "    for i in range(len(t) - len(p) + 1):  # loop over alignments\n",
    "        num_alignments += 1\n",
    "        match = True\n",
    "        for j in range(len(p)):  # loop over characters\n",
    "            num_character_comparisons += 1\n",
    "            if t[i+j] != p[j]:  # compare characters\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)  # all chars matched; record\n",
    "    return occurrences, num_alignments, num_character_comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] 41 46\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "###########\n",
    "p = 'word'\n",
    "t = 'there would have been a time for such a word'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 19] 20 35\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "###########\n",
    "p = 'needle'\n",
    "t = 'needle need noodle needle'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programming HW2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Genome from FASTA file#\n",
    "#############################\n",
    "\n",
    "def readGenome(filename):\n",
    "    \"\"\" This function reads a FASTA file\"\"\"\n",
    "    genome = '' # initialize genome to empty string\n",
    "    with open(filename,'r') as f:               # Open file as f\n",
    "        for line in f:                          # Loop therough and read each line of file f\n",
    "            if not line[0] == '>':              # If line does not start with \">\"\n",
    "                genome += line.rstrip()         # Add line to the string genome, rstrip removes trailing whitespace from ends of string        \n",
    "        \n",
    "    return genome                               # After reading and adding all lines return the string genome\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TTGAATGCTG'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome = readGenome('chr1.GRCh38.excerpt.fasta')\n",
    "genome[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799954\n"
     ]
    }
   ],
   "source": [
    "# 1 How many alignments doe naive exact algorithm try\n",
    "p = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, genome)\n",
    "print(num_alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984143\n"
     ]
    }
   ],
   "source": [
    "# 2 How many character comparisons doe naive exact matching algorithm try\n",
    "\n",
    "t = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, genome)\n",
    "print(num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boyer Moore with counts function\n",
    "##################################\n",
    "def boyer_moore_with_counts(p, p_bm, t):\n",
    "    \"\"\" Do Boyer-Moore matching. p=pattern, t=text,\n",
    "        p_bm=BoyerMoore object for p \"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    num_alignments = 0\n",
    "    num_character_comparisons = 0\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        num_alignments += 1\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            num_character_comparisons += 1\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurrences, num_alignments, num_character_comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessig module for Boyer Moore\n",
    "import bm_preproc\n",
    "from bm_preproc import BoyerMoore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922] 127974 165191\n",
      "number of alignments tried: 127974\n"
     ]
    }
   ],
   "source": [
    "# 3 How many alignments does Boyer Moore try\n",
    "p = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "p_bm = BoyerMoore(p, alphabet = 'ACGT')\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, genome)\n",
    "print(occurrences, num_alignments, num_character_comparisons)\n",
    "print('number of alignments tried:', num_alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] 12 15\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "###########\n",
    "p = 'word'\n",
    "t = 'there would have been a time for such a word'\n",
    "lowercase_alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Index-assisted approximate matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bisect module\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index(object):\n",
    "    def __init__(self, t, k):\n",
    "        ''' Create index from all substrings of size 'length' '''\n",
    "        self.k = k  # k-mer length (k)\n",
    "        self.index = []\n",
    "        for i in range(len(t) - k + 1):  # for each k-mer\n",
    "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
    "        self.index.sort()  # alphabetize by k-mer\n",
    "    \n",
    "    def query(self, p):\n",
    "        ''' Return index hits for first k-mer of P '''\n",
    "        kmer = p[:self.k]  # query with first k-mer\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search, -1 means we get all indices greater than -1 , ie the first occurence of that kmer\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != kmer:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Index object to match a full pattern in a string t\n",
    "\n",
    "def queryIndex(p, t, index): # Query fuction takes input pattern, string and index we created from t\n",
    "    k = index.k # get the length of k from the index we created\n",
    "    offsets = [] #List of offsets where it matches\n",
    "    for i in index.query(p): # the query function from the Index object returns a list of possible places in t where p could start,\n",
    "        if p[k:] == t[i+k:i+len(p)]:    #The query function gives us where the 1st k bases of p match k bases of t. \n",
    "            if i not in offsets:\n",
    "                offsets.append(i)           #But we need to VERIFY if the rest of the string p matches t in that location\n",
    "    return offsets                      # example: t=\"TAGACTAC\",p=\"ACTA\", i=3, k=3, p[k:]->p[3:]->'A'\n",
    "                                        # t[i+k:i+len(p)]->t[6:3+4]->t[6:7]->'A'\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = Index(genome, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_match(p, t, n):   #Takes as arguments pattern, text and the max number of mismatches n\n",
    "    \n",
    "    segment_length = int(round(len(p) /(n+1))) # Set the length of each partition of p, convert to int so that indices are int or it will raise error\n",
    "    all_matches = set() # create a set to hold all the indices wehere we find a match, wihtout duplicates\n",
    "    for i in range(n+1): # For each segment of P, for each iteration move along by the lenght of 1 segment\n",
    "        #Set bounds of P for the segment we are searching for \n",
    "        start = i * segment_length # so if i = 0 and seg_l = 2, start = 0, i = 1, seg_l= 2, start = 1 * 2\n",
    "        end = min((i+1) * segment_length, len(p)) #to make sure we dont run over end of p, since p might not be a perfect multiple of n+1\n",
    "        #Find matches where the substring matched our text\n",
    "        all_matches = queryIndex(p, t, index)     \n",
    "    return list(all_matches)         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsequence Index that handles subsequences that take every Nth character\n",
    "\n",
    "import bisect\n",
    "   \n",
    "class SubseqIndex(object):\n",
    "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
    "    \n",
    "    def __init__(self, t, k, ival):\n",
    "        \"\"\" Create index from all subsequences consisting of k characters\n",
    "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
    "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
    "        self.k = k  # num characters per subsequence extracted\n",
    "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
    "        self.index = []\n",
    "        self.span = 1 + ival * (k - 1)\n",
    "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
    "            self.index.append((t[i:i+self.span:ival], i))  # add (subseq, offset)\n",
    "        self.index.sort()  # alphabetize by subseq\n",
    "    \n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
    "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
    "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != subseq:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = genome\n",
    "subseq_ind = SubseqIndex(t, 8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_subseq(p, t, subseq_ind):\n",
    "    k = subseq_ind.k\n",
    "    offsets = []\n",
    "    num_index_hits = 0\n",
    "    for i in subseq_ind.query(p): \n",
    "        num_index_hits += 1\n",
    "        if p[k:] == t[i+k:i+len(p)]:\n",
    "            offsets.append(i)\n",
    "    return offsets, num_index_hits        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AAA', 0), ('TTT', 1)]\n"
     ]
    }
   ],
   "source": [
    "ind = SubseqIndex('ATATAT', 3, 2)\n",
    "print(ind.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "p = 'TTATAT'\n",
    "print(ind.query(p[0:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(ind.query(p[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_match(p, t, n):   #Takes as arguments pattern, text and the max number of mismatches n\n",
    "    \n",
    "    segment_length = int(round(len(p) /(n+1))) # Set the length of each partition of p, convert to int so that indices are int or it will raise error\n",
    "    all_matches = set() # create a set to hold all the indices wehere we find a match, wihtout duplicates\n",
    "    for i in range(n+1): # For each segment of P, for each iteration move along by the lenght of 1 segment\n",
    "        #Set bounds of P for the segment we are searching for \n",
    "        start = i * segment_length # so if i = 0 and seg_l = 2, start = 0, i = 1, seg_l= 2, start = 1 * 2\n",
    "        end = min((i+1) * segment_length, len(p)) #to make sure we dont run over end of p, since p might not be a perfect multiple of n+1\n",
    "        #Find matches where the substring matched our text\n",
    "        all_matches = subseq_ind(p, t, index)     \n",
    "    return list(all_matches)         \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
